{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCqoqXs9UzdbqhYFfACQjf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/not-adev/callAnalyser/blob/main/Callanalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"faster-whisper @ git+https://github.com/guillaumekln/faster-whisper.git\" yt-dlp ffmpeg-python\n",
        "#installing neccasry libraries and modules\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-nV1-xeToXb",
        "outputId": "2abad994-dba3-4cb8-d993-bc349d2787e3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.8/38.8 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for faster-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# library to download the required youtube video mentioned in assigment\n",
        "import yt_dlp\n",
        "\n",
        "def download_audio(youtube_url, output_path=\"audio.wav\"): #funtion to downloand\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'outtmpl': output_path,\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([youtube_url])\n",
        "\n",
        "# Example usage\n",
        "download_audio(\"https://www.youtube.com/watch?v=4ostqJD3Psc\") #calling funtion to download"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1JqvqzBiOKY",
        "outputId": "1f71c76e-42fc-46e6-86b9-28d6438fc242"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=4ostqJD3Psc\n",
            "[youtube] 4ostqJD3Psc: Downloading webpage\n",
            "[youtube] 4ostqJD3Psc: Downloading tv simply player API JSON\n",
            "[youtube] 4ostqJD3Psc: Downloading tv client config\n",
            "[youtube] 4ostqJD3Psc: Downloading player 0e6689e2-main\n",
            "[youtube] 4ostqJD3Psc: Downloading tv player API JSON\n",
            "[info] 4ostqJD3Psc: Downloading 1 format(s): 251\n",
            "[download] Sleeping 2.00 seconds as required by the site...\n",
            "[download] Destination: audio.wav\n",
            "[download] 100% of    1.99MiB in 00:00:00 at 7.49MiB/s   \n",
            "[ExtractAudio] Destination: audio.wav.wav\n",
            "Deleting original file audio.wav (pass -k to keep)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8aqVMnzqEHbd"
      },
      "outputs": [],
      "source": [
        "from faster_whisper import WhisperModel # importing whisper model for speech to text conversrion\n",
        "model = WhisperModel(\"base\", device=\"cpu\") #model intitalization\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "segments,info = model.transcribe(\"audio.wav.wav\", vad_filter=True ,word_timestamps=True ) # converting speech to text with time stamp"
      ],
      "metadata": {
        "id": "Vv8xw8NsGNpY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = [] # list to store speaker and their text\n",
        "keywords = (\"hi\", \"hello\", \"thank\")\n",
        "for seg in segments: #looping over all text or speeches in the video\n",
        "    speaker = \"Speaker A\" if any(kw in seg.text.lower() for kw in keywords) else \"Speaker B\" # identifying caller or reciever\n",
        "    transcript.append({\n",
        "        \"start\": seg.start,\n",
        "        \"end\": seg.end,\n",
        "        \"text\": seg.text,\n",
        "        \"speaker\": speaker\n",
        "    })\n"
      ],
      "metadata": {
        "id": "e6pLmgnkGohO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict # defalut dictionary to store time of each speaker\n"
      ],
      "metadata": {
        "id": "OohiaRveKCwz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "talk_time = defaultdict(float) # initialyzing disctionary\n"
      ],
      "metadata": {
        "id": "JYaJotlhKdbv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seg in transcript : # loopring over speaker text to find the total time taken by each speaker\n",
        "  talk_time[seg[\"speaker\"]] += seg[\"end\"] - seg[\"start\"]"
      ],
      "metadata": {
        "id": "M0n4eUPoKkum"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_time = sum(talk_time.values()) # total time of conversation"
      ],
      "metadata": {
        "id": "1GXzHkMtK6i8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in talk_time : # identifying ratio of each speaker\n",
        "  print(f'{i} : {talk_time[i]/total_time*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVlo9_XXLBxh",
        "outputId": "3a752511-52e4-45a2-fcfd-109533c6a37c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speaker A : 41.04%\n",
            "Speaker B : 58.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Number_of_question = 0 # initializing number of question"
      ],
      "metadata": {
        "id": "ZFU5oJKJMH-0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seg in transcript: # looping of transcript to find if their is any question found in conversation\n",
        "  if \"?\" in seg[\"text\"] : # if ? found in sentence increase the number of question\n",
        "    Number_of_question += 1\n",
        "print(f'number of question asked {Number_of_question}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuXQmwNcLtDf",
        "outputId": "84e01cf9-fac1-4523-becf-320ffad68509"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of question asked 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Longest_monolog = {\"speaker\" : \"null\" , \"time\" : 0 } # dictonary to identify spaeker and longest monolog\n",
        "for speaker in talk_time: # looping over  talk_time of each speaker\n",
        "  if talk_time[speaker] > Longest_monolog[\"time\"] : # if speaker talk time is greater then current longest monolog then change speaker and monologe time\n",
        "    Longest_monolog[\"time\"] = talk_time[speaker]\n",
        "    Longest_monolog[\"speaker\"] = speaker\n",
        "print(f'Longest monolog is {Longest_monolog[\"time\"]} by {Longest_monolog[\"speaker\"]} ')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gJFz3lRMiXn",
        "outputId": "644014bf-2558-4bdc-9a96-b7a3b4682d26"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longest monolog is 54.459999999999994 by Speaker B \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline # importing library for sentiment analysis"
      ],
      "metadata": {
        "id": "aCDg0mFpOWi1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_for_sentiment = pipeline(\"sentiment-analysis\") # initializing modle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs3HToLoQL-Z",
        "outputId": "ac0cabe9-8d50-4016-b4c5-4182802844ee"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" \".join(seg[\"text\"] for seg in transcript) # convert all text into a single string"
      ],
      "metadata": {
        "id": "LnkK-ftfQoLn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentimenst = model_for_sentiment(text[:512])[0] # extract the firts element from the sentiment\n",
        "print(f\"sentiment of the entire conversation is {sentimenst['label']} with score fo {sentimenst['score']}\")\n"
      ],
      "metadata": {
        "id": "x0NtbHYvQ3xs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1152464-6185-4aab-8ce8-2106a808b461"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment of the entire conversation is POSITIVE with score fo 0.9986336827278137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if talk_time[\"Rep\"]/total_time > 0.7: # simple insite machanizm\n",
        "    print(\"Insight: Let the customer speak more.\")\n",
        "elif Number_of_question < 3:\n",
        "    print(\"Insight: Ask more open-ended questions.\")\n",
        "else:\n",
        "    print(\"Insight: Good engagement. Consider summarizing key points.\")"
      ],
      "metadata": {
        "id": "SJg0qLH4R4Yk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4342a073-256c-4f5b-c0be-2e06e0ab0c53"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insight: Good engagement. Consider summarizing key points.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"speaker A is reciver and speaker B is the caller \")"
      ],
      "metadata": {
        "id": "uOAuvQAFTWxg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}